{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"item41\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concrete Crack Detector with a Neural Net\n",
    "### By Joshua Montgomery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains all the code required to train and test the model, however it did take 16 hours to execute on my laptop, so I would have to advise against trying to run the code yourself. Instead I will upload this notebook to GitHub and you will be able to see my outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set used to test and train this model consists of almost 40,000 images. There is an even split of positve images (cracked concrete) and negative (not cracket concrete) images. This data set is dowloaded from the URL below and then unzipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget  --no-check-certificate https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0321EN/data/concrete_data_week4.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip concrete_data_week4.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the dataset has been unzipped you will find it is already split into training and validation sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Initialising the model  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "To reduce traing time the partially trained VGG16 model will be used. This model is included in the keras open source package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.applications import VGG16\n",
    "from keras.applications.resnet50 import preprocess_input\n",
    "# Imports all of the required plug-ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2 #Positve or Negative\n",
    "image_resize = 224  #The images need to be resized so they are a fixed dimension\n",
    "batch_size_training = 100 \n",
    "batch_size_validation = 100\n",
    "# This section of code defines several key values that are used in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30001 images belonging to 2 classes.\n",
      "Found 9501 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "#This ImageDataGenerator 'data_generator' will be called as the parent for subsequent generators\n",
    "\n",
    "train_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week4/train',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_training,\n",
    "    class_mode='categorical')\n",
    "#The 'train_generator' is called when the model is being trained and contains 30,001 images\n",
    "\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week4/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    batch_size=batch_size_validation,\n",
    "    class_mode='categorical')\n",
    "#The 'validation_generator' is called when the model is being tested and contains 9,501 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Joshu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(VGG16(\n",
    "    include_top=False,\n",
    "    pooling='avg',\n",
    "    weights='imagenet',\n",
    "    ))\n",
    "# The model is intialised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 512)               14714688  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 14,715,714\n",
      "Trainable params: 1,026\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "model.layers[0].trainable = False\n",
    "model.summary()\n",
    "# The summary of the pretraining of the VGG16 model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the VGG16 model will be trained on the image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "steps_per_epoch_training = len(train_generator)\n",
    "steps_per_epoch_validation = len(validation_generator)\n",
    "num_epochs = 2 # More epochs would be better, however each epoch takes approximately 7 hours to exectute using my current hardware.\n",
    "# Compiling the model is the final step before fitting and defines the remaining inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_history = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch_training,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=steps_per_epoch_validation,\n",
    "    verbose=1,\n",
    "\n",
    "#By verbose is stated equal to 1, whilst fitting the code outputs various details such as cuurent accuracy, loss and an\n",
    "# expected time of completion. The code will run silently if verbose =0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('classifier_VGG16.h5')\n",
    "# This line of code saves the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Joshu\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshu\\anaconda3\\lib\\site-packages\\keras\\engine\\saving.py:384: UserWarning: Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "  warnings.warn('Error in loading the saved optimizer '\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"classifier_resnet_VGG16.h5\")\n",
    "# If the model has been saved into the working directory it can be loaded using this line of code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9501 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "data_generator = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    ")\n",
    "validation_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week4/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    #batch_size=batch_size_validation,\n",
    "    #class_mode='categorical',\n",
    "    shuffle=False)\n",
    "\n",
    "# These data generators are very similar to the previously defined generators, except shuffle is now equal to false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalmodelvgg16=model.evaluate_generator(validation_generator)\n",
    "# This code evaluates the model, and can take a while to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of the VGG16 model is 0.00083 and the accuarcy is 99.6%\n",
      "The loss of the ResNet50 model is 0.0 and the accuarcy is 82.0%\n"
     ]
    }
   ],
   "source": [
    "print('The loss of the VGG16 model is ' + str(round(evalmodelvgg16[0], 5))+ ' and the accuarcy is '+ str(100*round(evalmodelvgg16[1],3)) +'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9501 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "predictor_generator = data_generator.flow_from_directory(\n",
    "    'concrete_data_week4/valid',\n",
    "    target_size=(image_resize, image_resize),\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictvgg16=model.predict_generator(predictor_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_predictions=len(predictvgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Negative', 'Negative', 'Negative', 'Negative', 'Negative']\n"
     ]
    }
   ],
   "source": [
    "predictions=[]\n",
    "for i in range (0,number_of_predictions):\n",
    "    if predictvgg16[i][0]>predictvgg16[i][1]:\n",
    "        predictions.append('Negative')\n",
    "    else:\n",
    "        predictions.append('Positive')\n",
    "\n",
    "print(predictions[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the downloaded file had two sub folders containing all the images, with the negative folder first, almost all the predictions are negative. Untill the subfolder switches to the positive folder and then almost all the predictions are postive.\n",
    "I've also printed the last five predicitons as proof of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Positive', 'Positive', 'Positive', 'Positive', 'Positive']\n"
     ]
    }
   ],
   "source": [
    "print(predictions[(number_of_predictions-5):number_of_predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The full list of output predictions, shows that almost all of the predicitons are correct, in line with the predicted accuracy of 99.6%\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
